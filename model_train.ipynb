{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7d45e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import time\n",
    "import joblib\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold, GridSearchCV, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import lightgbm as lgbm\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc2a3440",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "# Loading cleaned training data\n",
    "data = pd.read_csv('./files/training_features_cleaned.csv')\n",
    "X = data.drop(columns='CLASS_LABEL')\n",
    "y = data['CLASS_LABEL']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c76eb30",
   "metadata": {},
   "source": [
    "Given the relatively small size of the dataset, we adopted a 5‑fold cross‑validation strategy for all model training and evaluation. This approach ensures more reliable performance estimates and reduces the risk of overfitting. For this dataset, we focused on evaluating four ML algorithms: \n",
    "K‑Nearest Neighbors (KNN), \n",
    "Random Forest, \n",
    "Decision Tree,\n",
    "LightGBM. \n",
    "As an initial step, each model was tested using default parameters to validate the implementation and establish baseline performance scores before proceeding with further tuning and optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d71702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN - Mean Accuracy: 0.9410, Std Dev: 0.0056\n",
      "RandomForest - Mean Accuracy: 0.9777, Std Dev: 0.0037\n",
      "DecisionTree - Mean Accuracy: 0.9634, Std Dev: 0.0038\n",
      "LightGBM - Mean Accuracy: 0.9827, Std Dev: 0.0025\n",
      "\n",
      "Summary of Model Performances:\n",
      "          Model  Mean Accuracy   Std Dev\n",
      "3      LightGBM       0.982714  0.002531\n",
      "1  RandomForest       0.977714  0.003709\n",
      "2  DecisionTree       0.963429  0.003844\n",
      "0           KNN       0.941000  0.005581\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "models = {\n",
    "    'KNN': Pipeline([\n",
    "        ('scaler', MinMaxScaler()), \n",
    "        ('clf', KNeighborsClassifier(n_neighbors=5))\n",
    "        ]),\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'DecisionTree': DecisionTreeClassifier(random_state=42),\n",
    "    'LightGBM': Pipeline([\n",
    "        ('scaler', MinMaxScaler()), \n",
    "        ('clf', lgbm.LGBMClassifier(random_state=42, verbose=-1))\n",
    "        ])\n",
    "}\n",
    "\n",
    "results = []\n",
    "for model_name, model in models.items():\n",
    "    cv_results = cross_val_score(model, X.values, y.values, cv=kf, scoring='accuracy')\n",
    "    results.append({\n",
    "        'Model': model_name,\n",
    "        'Mean Accuracy': cv_results.mean(),\n",
    "        'Std Dev': cv_results.std()\n",
    "    })\n",
    "    print(f\"{model_name} - Mean Accuracy: {cv_results.mean():.4f}, Std Dev: {cv_results.std():.4f}\")\n",
    "\n",
    "summary_df = pd.DataFrame(results).sort_values(by='Mean Accuracy', ascending=False) \n",
    "print(\"\\nSummary of Model Performances:\")\n",
    "print(summary_df)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ac2bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running GridSearch for KNN ===\n",
      "\n",
      "=== Running GridSearch for Random Forest ===\n",
      "\n",
      "=== Running GridSearch for Decision Tree ===\n",
      "\n",
      "=== Running GridSearch for LightGBM ===\n",
      "\n",
      "=== Final Summary Table ===\n",
      "           Model  Best Accuracy  \\\n",
      "0       LightGBM         0.9844   \n",
      "1  Random Forest         0.9791   \n",
      "2  Decision Tree         0.9677   \n",
      "3            KNN         0.9539   \n",
      "\n",
      "                                                                                                                                                                          Best Parameters  \\\n",
      "0  {'clf__colsample_bytree': 0.8, 'clf__learning_rate': 0.1, 'clf__max_depth': -1, 'clf__min_child_samples': 10, 'clf__n_estimators': 200, 'clf__num_leaves': 127, 'clf__subsample': 0.8}   \n",
      "1                                                  {'clf__max_depth': 20, 'clf__max_features': 'log2', 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 2, 'clf__n_estimators': 100}   \n",
      "2                                                                               {'clf__criterion': 'gini', 'clf__max_depth': 10, 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 2}   \n",
      "3                                                                                                         {'clf__metric': 'manhattan', 'clf__n_neighbors': 3, 'clf__weights': 'distance'}   \n",
      "\n",
      "   Time (s)  \n",
      "0  21678.10  \n",
      "1    277.32  \n",
      "2      1.16  \n",
      "3      3.49  \n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define models as pipelines\n",
    "model_defs = {\n",
    "    \"KNN\": Pipeline([(\"scaler\", MinMaxScaler()), (\"clf\", KNeighborsClassifier())]),\n",
    "    \"Random Forest\": Pipeline([(\"clf\", RandomForestClassifier(random_state=42))]),\n",
    "    \"Decision Tree\": Pipeline([(\"clf\", DecisionTreeClassifier(random_state=42))]),\n",
    "    \"LightGBM\": Pipeline([(\"scaler\", MinMaxScaler()), (\"clf\", lgbm.LGBMClassifier(random_state=42, verbose=-1))])\n",
    "}\n",
    "\n",
    "# Parameter grids (same as your definition)\n",
    "param_grids = {\n",
    "    \"KNN\": {\n",
    "        'clf__n_neighbors': [1, 3, 5, 7, 9],\n",
    "        'clf__weights': ['uniform', 'distance'],\n",
    "        'clf__metric': ['euclidean', 'manhattan']\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        'clf__max_depth': [10, 20, 30, None],\n",
    "        'clf__n_estimators': [100, 200, 300],\n",
    "        'clf__min_samples_split': [2, 5, 10],\n",
    "        'clf__min_samples_leaf': [1, 2, 4],\n",
    "        'clf__max_features': ['sqrt', 'log2', None]\n",
    "    },\n",
    "    \"Decision Tree\": {\n",
    "        'clf__max_depth': [5, 10, 15, None],\n",
    "        'clf__min_samples_split': [2, 5, 10],\n",
    "        'clf__min_samples_leaf': [1, 2, 5],\n",
    "        'clf__criterion': ['gini', 'entropy']\n",
    "    },\n",
    "    \"LightGBM\": {\n",
    "        'clf__learning_rate': [0.01, 0.05, 0.1],\n",
    "        'clf__n_estimators': [100, 200],\n",
    "        'clf__num_leaves': [31, 63, 127],\n",
    "        'clf__max_depth': [-1, 10, 20],\n",
    "        'clf__min_child_samples': [10, 20, 30],\n",
    "        'clf__subsample': [0.8, 1.0],\n",
    "        'clf__colsample_bytree': [0.8, 1.0],\n",
    "    }\n",
    "}\n",
    "\n",
    "summary = {\"Model\": [], \"Best Accuracy\": [], \"Best Parameters\": [], \"Time (s)\": []}\n",
    "\n",
    "for name, pipe in model_defs.items():\n",
    "    print(f\"\\n=== Running GridSearch for {name} ===\")\n",
    "    start = time.time()\n",
    "    grid = GridSearchCV(pipe, param_grids[name], cv=kf, scoring=\"accuracy\", n_jobs=-1, verbose=0)\n",
    "    grid.fit(X, y)\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    summary[\"Model\"].append(name)\n",
    "    summary[\"Best Accuracy\"].append(grid.best_score_)\n",
    "    summary[\"Best Parameters\"].append(grid.best_params_)\n",
    "    summary[\"Time (s)\"].append(round(elapsed, 2))\n",
    "\n",
    "summary_df = pd.DataFrame(summary)\n",
    "summary_df[\"Best Accuracy\"] = summary_df[\"Best Accuracy\"].round(4)\n",
    "summary_df = summary_df.sort_values(by=\"Best Accuracy\", ascending=False).reset_index(drop=True)\n",
    "summary_df[\"Best Parameters\"] = summary_df[\"Best Parameters\"].apply(lambda d: str(d))\n",
    "\n",
    "print(\"\\n=== Final Summary Table ===\")\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "print(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e43a49d",
   "metadata": {},
   "source": [
    "A large range of parameters was tested and, for what was already the model wih the best accuracy results on the first run (LightGBM), there as been only an increase from 0.982714 to 0.9844. Given the small gain in accuracy (0.17%) over what took a significant computational time (21678s) it's not worth to test more parameters on these models. \n",
    "\n",
    "One thing worth testing on LightGBM with these optimized parameters is to enable early stopping, as running the training for the full number of runs can lead to overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60c2395f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== LightGBM Early-Stop KFold Validation Summary ===\n",
      "Mean Accuracy: 0.9809\n",
      "Std Dev: 0.0038\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'objective': 'binary' if len(y.unique()) == 2 else 'multiclass',\n",
    "    'num_class': len(y.unique()) if len(y.unique()) > 2 else 1,\n",
    "    'metric': 'binary_logloss' if len(y.unique()) == 2 else 'multi_logloss',\n",
    "    'verbosity': -1,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'seed': 42,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': -1,\n",
    "    'min_child_samples': 10,\n",
    "    'n_estimators': 200,\n",
    "    'num_leaves': 127,\n",
    "    'subsample': 0.8\n",
    "}\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "results = []\n",
    "fold_num = 1\n",
    "\n",
    "for train_index, val_index in kf.split(X):\n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "    train_data = lgbm.Dataset(X_train_scaled, label=y_train)\n",
    "    val_data = lgbm.Dataset(X_val_scaled, label=y_val, reference=train_data)\n",
    "\n",
    "    gbm = lgbm.train(\n",
    "        params,\n",
    "        train_data,\n",
    "        valid_sets=[val_data],\n",
    "        num_boost_round=200,\n",
    "        callbacks=[lgbm.early_stopping(stopping_rounds=10, verbose=False)]\n",
    "    )\n",
    "\n",
    "    y_pred_prob = gbm.predict(X_val_scaled, num_iteration=gbm.best_iteration)\n",
    "    if len(y.unique()) > 2:\n",
    "        y_pred = y_pred_prob.argmax(axis=1)\n",
    "    else:\n",
    "        y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    results.append(acc)\n",
    "\n",
    "    fold_num += 1\n",
    "\n",
    "print(\"\\n=== LightGBM Early-Stop KFold Validation Summary ===\")\n",
    "print(f\"Mean Accuracy: {np.mean(results):.4f}\")\n",
    "print(f\"Std Dev: {np.std(results):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8bc0ef",
   "metadata": {},
   "source": [
    "Although the accuracy is lower than before, this might still be a better model for general use since before we could be overfitting the model the this training data, causing it to be worst for data outside this.\n",
    "Since the work of hyperparameter tuning has been done for all models, I will save all optimized models in disk. For the final train of the model all data from the dataset is used, instead of using k-fold like we have done during tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f4707eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./models/lightgbm_best_es.pkl']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_pipeline = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('clf', lgbm.LGBMClassifier(\n",
    "        colsample_bytree=0.8,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=-1,\n",
    "        min_child_samples=10,\n",
    "        n_estimators=200,\n",
    "        num_leaves=127,\n",
    "        subsample=0.8,\n",
    "        objective='binary' if len(y.unique()) == 2 else 'multiclass',\n",
    "        random_state=42,\n",
    "        verbosity=-1\n",
    "    ))\n",
    "])\n",
    "lgbm_pipeline.fit(X, y)\n",
    "joblib.dump(lgbm_pipeline, './models/lightgbm.pkl')\n",
    "\n",
    "\n",
    "best_params = {\n",
    "    'colsample_bytree': 0.8,\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': -1,\n",
    "    'min_child_samples': 10,\n",
    "    'n_estimators': 200,\n",
    "    'num_leaves': 127,\n",
    "    'subsample': 0.8,\n",
    "    'random_state': 42,\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "# Pipeline with scaler + LightGBM\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('clf', lgbm.LGBMClassifier(**best_params))\n",
    "])\n",
    "\n",
    "pipeline.fit(\n",
    "    X, y,\n",
    "    clf__eval_set=[(X, y)],\n",
    "    clf__eval_metric=\"accuracy\",\n",
    "    clf__callbacks=[lgbm.early_stopping(stopping_rounds=10, verbose=False)]\n",
    ")\n",
    "\n",
    "joblib.dump(pipeline, './models/lightgbm_best_es.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79adab01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./models/lgbm_es.pkl']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = {\n",
    "    'KNN': Pipeline([\n",
    "        ('scaler', MinMaxScaler()),\n",
    "        ('clf', KNeighborsClassifier(n_neighbors=3, weights='distance', metric='manhattan'))\n",
    "    ]),\n",
    "    'RandomForest': Pipeline([\n",
    "        ('clf', RandomForestClassifier(max_depth=20, max_features='log2',\n",
    "                                       min_samples_leaf=1, min_samples_split=2,\n",
    "                                       n_estimators=100, random_state=42))\n",
    "    ]),\n",
    "    'DecisionTree': Pipeline([\n",
    "        ('clf', DecisionTreeClassifier(max_depth=10, min_samples_split=2,\n",
    "                                       min_samples_leaf=1, criterion='gini',\n",
    "                                       random_state=42))\n",
    "    ]),\n",
    "    'LGBM': Pipeline([\n",
    "        ('scaler', MinMaxScaler()),\n",
    "        ('clf', lgbm.LGBMClassifier(colsample_bytree=0.8, learning_rate=0.1,\n",
    "                               max_depth=-1, min_child_samples=10,\n",
    "                               n_estimators=200, num_leaves=127, subsample=0.8,\n",
    "                               objective='binary' if len(y.unique()) == 2 else 'multiclass',\n",
    "                               random_state=42, verbosity=-1))\n",
    "    ])\n",
    "}\n",
    "lgbm_es = models['LGBM']\n",
    "\n",
    "for name, model in models.items():\n",
    "    joblib.dump(model.fit(X, y), f'./models/{name.lower()}.pkl')\n",
    "\n",
    "lgbm_es.fit(X, y, clf__eval_set=[(X, y)], clf__eval_metric=\"accuracy\", clf__callbacks=[lgbm.early_stopping(stopping_rounds=10, verbose=False)])\n",
    "joblib.dump(lgbm_es, './models/lgbm_es.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a008a5",
   "metadata": {},
   "source": [
    "It's now time to properly test the models agaist the \"test\" data we have separated at the beginning, which as never been 'seen' by the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70fca279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Model Evaluation on Test Set ===\n",
      "          Model  Accuracy  Precision  Recall  F1-Score    TP    TN  FP  FN\n",
      "0          LGBM    0.9833     0.9833  0.9833    0.9833  1473  1477  23  27\n",
      "1       LGBM_es    0.9797     0.9797  0.9797    0.9797  1473  1466  34  27\n",
      "2  RandomForest    0.9780     0.9780  0.9780    0.9780  1465  1469  31  35\n",
      "3  DecisionTree    0.9637     0.9637  0.9637    0.9637  1450  1441  59  50\n",
      "4           KNN    0.9610     0.9615  0.9610    0.9610  1466  1417  83  34\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "test_data = pd.read_csv('./files/testing_features_cleaned.csv')\n",
    "X_test = test_data.drop(columns='CLASS_LABEL')\n",
    "y_test = test_data['CLASS_LABEL']\n",
    "\n",
    "model_paths = {\n",
    "    'KNN': './models/knn.pkl',\n",
    "    'RandomForest': './models/randomforest.pkl',\n",
    "    'DecisionTree': './models/decisiontree.pkl',\n",
    "    'LGBM': './models/lgbm.pkl',\n",
    "    'LGBM_es': './models/lgbm_es.pkl'\n",
    "}\n",
    "\n",
    "models = {name: joblib.load(path) for name, path in model_paths.items()}\n",
    "\n",
    "def evaluate_model(model, X, y, name):\n",
    "    y_pred = model.predict(X)\n",
    "    acc = accuracy_score(y, y_pred)\n",
    "    pr = precision_score(y, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n",
    "\n",
    "    return {\n",
    "        'Model': name,\n",
    "        'Accuracy': round(acc, 4),\n",
    "        'Precision': round(pr, 4),\n",
    "        'Recall': round(rec, 4),\n",
    "        'F1-Score': round(f1, 4),\n",
    "        'TP': tp,\n",
    "        'TN': tn,\n",
    "        'FP': fp,\n",
    "        'FN': fn\n",
    "    }\n",
    "\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    result = evaluate_model(model, X_test, y_test, name)\n",
    "    results.append(result)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values(by='Accuracy', ascending=False).reset_index(drop=True)\n",
    "print(\"\\n=== Model Evaluation on Test Set ===\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e468b01",
   "metadata": {},
   "source": [
    "As expected, we have the best results with the LightGBM model. Although RandomForest is close in terms of accuracy, the FP/FN ratio is lower. If we think the model goal is to detect malicious URL's, from a security perspective it is preferred to have more FP (legitimate URL flagged as malicioous) than FN (malicious URL flagged as legitimate)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
